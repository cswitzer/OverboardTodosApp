worker_processes 1; # should be equal to the number of CPU cores

events {
    # each worker can handle up to 1024 simultaneous connections. The more connections
    # there are, the more memory is used.
    worker_connections 1024;
}

http {
    # enable nginx's gzip compression to reduce the size of responses to the client
    # the higher the compression level, the more CPU is used. 2 is a reasonable compromise
    # if the response is smaller than 512 bytes, don't bother compressing it
    gzip on;
    gzip_comp_level 2;
    gzip_min_length 512;

    # mime.types is a file that maps file extensions to MIME types
    # We want the client to know the type of file being served
    include mime.types;

    # If nginx cannot determine the file type, use this default which is a generic binary stream
    default_type application/octet-stream;

    # create a limit on the number of connections from a single IP address
    # the zone is stored in shared memory for all workers to access ip address data
    # we allocate 10 megabytes of memory for this zone at 10 requests per second
    limit_req_zone $binary_remote_addr zone=rootlimit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=flowerlimit:10m rate=5r/s;

    # return HTTP 429 if the limit is exceeded
    limit_req_status 429;

    # defines a group of backend servers running the same application that nginx can load balance requests to
    upstream fastapi_backend {
        # round robin is the default load balancing method;
        # each new request is sent to the next server in the list

        # web is the name of the service defined in docker-compose.yml
        server web:8000;
        # server web2:8000;
        # server web3:8000;
    }

    server {
        # listens on port 80 via docker compose configuration
        listen 80;
        # which domain is the client making the request to
        server_name localhost;
        client_max_body_size 20M;

        # if someone accesses localhost:80/, what should nginx do?
        location / {
            # apply the connection limit defined earlier
            # queue up to 20 requests if the limit is exceeded, but don't delay processing
            limit_req zone=rootlimit burst=20 nodelay;

            # forwards all request to / to the fastapi_backend group defined earlier
            # if there are multiple backend servers, nginx will load balance between them
            proxy_pass http://fastapi_backend;

            # send the original URL the client requested to the backend application
            proxy_set_header Host $host;

            # Send the original client's IP address to the backend instead of the IP address of the nginx server
            proxy_set_header X-Real-IP $remote_addr;

            # Tracks the chain of proxies the request has passed through so the backend can see all IP addresses involved
            # Could be useful when multiple proxies are used
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        # If someone accesses localhost:80/flower/, what should nginx do?
        location /flower/ {
            # apply the connection limit defined earlier
            limit_req zone=flowerlimit burst=10 nodelay;

            # since nginx runs in docker, it defines the flower service by its service name and port
            # since there is no trailing slash here, nginx will pass the /flower/ part of the URL to flower
            # this is why we need to set the --url_prefix=flower option when starting flower, otherwise
            # flower will try to load resources from /static/ which won't work
            proxy_pass http://flower:5555;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}